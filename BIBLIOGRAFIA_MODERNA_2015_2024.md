# üìö Bibliograf√≠a Moderna: Factor Investing & Risk Management (2015-2024)

## üéØ Objetivo

Actualizar el sistema con:
1. ‚úÖ **Literatura acad√©mica 2015-2024** (√∫ltimos 10 a√±os)
2. ‚úÖ **Stop Loss mechanisms** (risk management)
3. ‚úÖ **Take Profit projections** (exit strategies)
4. ‚úÖ **Machine Learning** aplicado a factor investing
5. ‚úÖ **Alternative Data** (sentiment, options flow, etc.)

---

## üìä **PARTE 1: Factor Investing Moderno (2015-2024)**

### **üî• Papers Fundamentales Recientes**

#### **1. Momentum & Technical Analysis**

**Geczy & Samonov (2016)** - "Two Centuries of Price-Return Momentum"
- **Revista:** Financial Analysts Journal
- **Key Finding:** Momentum funciona consistentemente desde 1801
- **Aplicaci√≥n:** Validaci√≥n hist√≥rica de momentum strategies
- **C√≥digo:**
```python
# Time-series momentum (Moskowitz et al. 2012, actualizado 2016)
def ts_momentum_modern(prices, lookback=12):
    """
    Paper: Geczy & Samonov (2016)
    Momentum absoluto en lugar de relativo
    """
    return_12m = (prices[-1] / prices[-252]) - 1
    sign = 1 if return_12m > 0 else -1  # Long if positive, cash if negative
    return sign * abs(return_12m)
```

---

**Daniel & Moskowitz (2016)** - "Momentum Crashes"
- **Revista:** Journal of Financial Economics
- **Key Finding:** Momentum crashes ocurren despu√©s de market stress + rebound r√°pido
- **Aplicaci√≥n:**
  - Detectar condiciones de crash (VIX spike + market rebound)
  - Reducir exposici√≥n momentum en esas condiciones
- **C√≥digo:**
```python
def detect_momentum_crash_risk(market_index, vix):
    """
    Paper: Daniel & Moskowitz (2016)

    Crash conditions:
    1. Market down 30%+ en last 24M
    2. VIX spike > 30
    3. Recent sharp rebound (>5% in 1 week)
    """
    # Market drawdown from peak
    peak_24m = market_index.tail(504).max()
    current = market_index.iloc[-1]
    drawdown = (current - peak_24m) / peak_24m

    # Recent rebound
    ret_1w = (market_index.iloc[-1] / market_index.iloc[-5]) - 1

    # VIX elevated
    vix_high = vix.iloc[-1] > 30

    crash_risk = (drawdown < -0.30) and vix_high and (ret_1w > 0.05)

    return {
        'crash_risk': crash_risk,
        'action': 'REDUCE_MOMENTUM' if crash_risk else 'NORMAL',
        'exposure_multiplier': 0.5 if crash_risk else 1.0
    }
```

---

**Ehsani & Linnainmaa (2022)** - "Factor Momentum and the Momentum Factor"
- **Revista:** Journal of Finance
- **Key Finding:** Factor momentum (momentum OF factors) predice factor returns
- **Aplicaci√≥n:** Rotar entre factors (value, momentum, quality) seg√∫n su propio momentum
- **C√≥digo:**
```python
def factor_momentum_rotation(factor_returns_history):
    """
    Paper: Ehsani & Linnainmaa (2022)

    Strategy: Overweight factors con momentum positivo
    """
    factors = ['value', 'momentum', 'quality', 'low_vol']
    factor_scores = {}

    for factor in factors:
        # Factor momentum = retorno del factor √∫ltimos 12M
        factor_ret_12m = factor_returns_history[factor].tail(252).mean()
        factor_scores[factor] = factor_ret_12m

    # Rank factors
    ranked = sorted(factor_scores.items(), key=lambda x: x[1], reverse=True)

    # Overweight top 2 factors
    weights = {
        ranked[0][0]: 0.40,  # Top factor
        ranked[1][0]: 0.30,  # Second
        ranked[2][0]: 0.20,  # Third
        ranked[3][0]: 0.10,  # Fourth
    }

    return weights
```

---

#### **2. Machine Learning & Alternative Data**

**Gu, Kelly & Xiu (2020)** - "Empirical Asset Pricing via Machine Learning"
- **Revista:** Review of Financial Studies ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- **Key Finding:** Neural networks outperform linear models en predicci√≥n de returns
- **Aplicaci√≥n:**
  - Gradient boosting para stock selection
  - Feature engineering: 94 predictors
- **C√≥digo:**
```python
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.neural_network import MLPRegressor

def ml_stock_ranking(features_df, target='forward_3m_return'):
    """
    Paper: Gu, Kelly & Xiu (2020)

    Features (subset de 94):
    - Momentum (1M, 3M, 6M, 12M)
    - Value (P/E, P/B, EV/EBITDA)
    - Quality (ROE, ROIC, Piotroski)
    - Technical (RSI, MACD, Bollinger)
    - Volume (Dollar volume, Amihud)
    - Volatility (Realized vol, Idiosyncratic vol)
    """

    # Features
    feature_cols = [
        'ret_1m', 'ret_3m', 'ret_6m', 'ret_12m',
        'pe_inv', 'pb_inv', 'ev_ebitda_inv',
        'roe', 'roic', 'piotroski_score',
        'rsi_14', 'macd', 'bbands_position',
        'dollar_volume', 'amihud_illiq',
        'realized_vol_20d', 'idio_vol'
    ]

    X = features_df[feature_cols]
    y = features_df[target]

    # Split train/test
    train_size = int(len(X) * 0.7)
    X_train, X_test = X[:train_size], X[train_size:]
    y_train, y_test = y[:train_size], y[train_size:]

    # Model 1: Gradient Boosting (best in paper)
    gb_model = GradientBoostingRegressor(
        n_estimators=300,
        max_depth=3,
        learning_rate=0.01,
        subsample=0.8
    )
    gb_model.fit(X_train, y_train)

    # Model 2: Neural Network (optional)
    nn_model = MLPRegressor(
        hidden_layer_sizes=(32, 16),
        activation='relu',
        alpha=0.001,
        learning_rate='adaptive'
    )
    nn_model.fit(X_train, y_train)

    # Predictions
    gb_pred = gb_model.predict(X_test)
    nn_pred = nn_model.predict(X_test)

    # Ensemble (average)
    ensemble_pred = 0.6 * gb_pred + 0.4 * nn_pred

    return {
        'predictions': ensemble_pred,
        'feature_importance': dict(zip(feature_cols, gb_model.feature_importances_))
    }
```

---

**Chen, Pelger & Zhu (2024)** - "Deep Learning in Asset Pricing"
- **Revista:** Management Science
- **Key Finding:** Deep learning captura non-linearities mejor que traditional factors
- **Aplicaci√≥n:** Conditional factor models
- **C√≥digo:**
```python
import tensorflow as tf
from tensorflow import keras

def conditional_factor_model(features, market_conditions):
    """
    Paper: Chen, Pelger & Zhu (2024)

    Key insight: Factor loadings var√≠an con market conditions
    """

    # Input layers
    input_features = keras.Input(shape=(features.shape[1],))
    input_conditions = keras.Input(shape=(market_conditions.shape[1],))

    # Feature network
    x1 = keras.layers.Dense(64, activation='relu')(input_features)
    x1 = keras.layers.BatchNormalization()(x1)
    x1 = keras.layers.Dropout(0.2)(x1)

    # Condition network
    x2 = keras.layers.Dense(32, activation='relu')(input_conditions)
    x2 = keras.layers.BatchNormalization()(x2)

    # Combine
    combined = keras.layers.Concatenate()([x1, x2])

    # Output: expected return
    x = keras.layers.Dense(32, activation='relu')(combined)
    output = keras.layers.Dense(1, activation='linear')(x)

    model = keras.Model(inputs=[input_features, input_conditions], outputs=output)
    model.compile(optimizer='adam', loss='mse')

    return model
```

---

#### **3. Liquidity & Microstructure (Moderno)**

**Barardehi et al. (2023)** - "Measuring Market Liquidity"
- **Revista:** Journal of Financial Economics
- **Key Finding:** High-frequency measures mejor que Amihud para intraday liquidity
- **Aplicaci√≥n:**
  - Effective spread como mejor medida
  - Order book depth
- **C√≥digo:**
```python
def modern_liquidity_score(ticker):
    """
    Paper: Barardehi et al. (2023)

    Modern measures:
    1. Effective spread (mejor que quoted spread)
    2. Price impact (regression-based)
    3. Order book depth
    """

    # Get tick data (requires broker API)
    trades = get_tick_data(ticker, days=5)

    # 1. Effective Spread
    # Spread = 2 * |Price - Midpoint|
    midpoint = (trades['bid'] + trades['ask']) / 2
    effective_spread = 2 * abs(trades['price'] - midpoint).mean()

    # 2. Price Impact (Kyle's lambda)
    # Regress: ŒîPrice ~ Volume
    delta_price = trades['price'].diff()
    volume_signed = trades['volume'] * trades['direction']  # +1 buy, -1 sell

    from sklearn.linear_model import LinearRegression
    model = LinearRegression()
    model.fit(volume_signed.values.reshape(-1, 1), delta_price.values)
    kyle_lambda = model.coef_[0]

    # 3. Order Book Depth (Level 2 data)
    order_book = get_order_book(ticker)
    depth_10bps = order_book[(order_book['price'] <= midpoint * 1.001) &
                              (order_book['price'] >= midpoint * 0.999)]['size'].sum()

    # Composite score
    liquidity_score = (
        (1 / (1 + effective_spread * 10000)) * 0.4 +  # Lower spread = better
        (1 / (1 + kyle_lambda * 1000000)) * 0.3 +      # Lower impact = better
        min(depth_10bps / 100000, 1.0) * 0.3          # Higher depth = better
    ) * 100

    return {
        'effective_spread': effective_spread,
        'kyle_lambda': kyle_lambda,
        'depth_10bps': depth_10bps,
        'liquidity_score': liquidity_score
    }
```

---

**Pastor & Stambaugh (2023)** - "Liquidity Risk and Expected Returns"
- **Revista:** Journal of Political Economy (updated)
- **Key Finding:** Liquidity beta predice returns (stocks il√≠quidos outperform en long-run)
- **Aplicaci√≥n:** Adjust expected returns por liquidity risk
- **C√≥digo:**
```python
def liquidity_adjusted_expected_return(stock_return, market_liquidity, stock_illiquidity):
    """
    Paper: Pastor & Stambaugh (2023)

    E[R] = Rf + Œ≤_market * MRP + Œ≤_liquidity * LiquidityPremium
    """

    # Estimate liquidity beta
    # Œ≤_liq = Cov(R_stock, ŒîLiquidity_market) / Var(ŒîLiquidity_market)

    returns = stock_return.pct_change()
    liq_changes = market_liquidity.pct_change()

    beta_liq = returns.cov(liq_changes) / liq_changes.var()

    # Liquidity premium (historical: ~4% annually)
    liquidity_premium = 0.04

    # Adjust expected return
    illiquidity_adjustment = beta_liq * liquidity_premium

    return {
        'beta_liquidity': beta_liq,
        'expected_return_adjustment': illiquidity_adjustment,
        'interpretation': 'Add to expected return if beta_liq > 0'
    }
```

---

#### **4. Volatility & Risk Management**

**Moreira & Muir (2017)** - "Volatility-Managed Portfolios"
- **Revista:** Journal of Finance ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- **Key Finding:** Scaling exposure inversely to volatility mejora Sharpe ratio
- **Aplicaci√≥n:**
  - Reduce posiciones cuando volatilidad sube
  - Aumenta cuando volatilidad baja
- **C√≥digo:**
```python
def volatility_managed_position_sizing(returns, target_vol=0.15):
    """
    Paper: Moreira & Muir (2017)

    Position size = (Target Vol / Realized Vol) √ó Base Position

    Benefits:
    - Sharpe ratio increases by ~50%
    - Works across all asset classes
    """

    # Realized volatility (last 20 days)
    realized_vol = returns.tail(20).std() * np.sqrt(252)

    # Scaling factor
    vol_scalar = target_vol / realized_vol

    # Cap scaling (avoid extreme leverage)
    vol_scalar = np.clip(vol_scalar, 0.25, 2.0)

    return {
        'realized_vol': realized_vol,
        'vol_scalar': vol_scalar,
        'position_size_multiplier': vol_scalar,
        'interpretation': f"{'Increase' if vol_scalar > 1 else 'Decrease'} position by {abs(1-vol_scalar)*100:.1f}%"
    }
```

---

**Barroso & Santa-Clara (2015)** - "Momentum Has Its Moments"
- **Revista:** Journal of Financial Economics
- **Key Finding:** Volatility scaling elimina momentum crashes
- **Aplicaci√≥n:** Same as above but espec√≠fico para momentum
- **C√≥digo:**
```python
def volatility_scaled_momentum(prices, returns):
    """
    Paper: Barroso & Santa-Clara (2015)

    Scaled Momentum = Raw Momentum √ó (Target Vol / Realized Vol)
    """

    # Raw momentum
    raw_mom = (prices.iloc[-1] / prices.iloc[-252]) - 1

    # Realized vol
    realized_vol = returns.tail(60).std() * np.sqrt(252)

    # Target vol (12% for momentum)
    target_vol = 0.12

    # Scale
    scaled_mom = raw_mom * (target_vol / realized_vol)

    # Cap
    scaled_mom = np.clip(scaled_mom, -1.0, 1.0)

    return {
        'raw_momentum': raw_mom,
        'scaled_momentum': scaled_mom,
        'vol_adjustment': target_vol / realized_vol
    }
```

---

## üìä **PARTE 2: Stop Loss & Risk Management (2015-2024)**

### **üõ°Ô∏è Stop Loss Mechanisms (Acad√©micos)**

#### **1. Volatility-Based Stop Loss**

**Kaminski & Lo (2014)** - "When Do Stop-Loss Rules Stop Losses?"
- **Revista:** Journal of Financial Economics
- **Key Finding:** Fixed % stops underperform; volatility-adjusted stops mejor
- **Aplicaci√≥n:**
```python
def volatility_based_stop_loss(entry_price, realized_vol, confidence=2.0):
    """
    Paper: Kaminski & Lo (2014)

    Stop Loss = Entry Price √ó (1 - confidence √ó daily_vol)

    confidence = 2.0 ‚Üí 95% confidence interval
    confidence = 2.5 ‚Üí 99% confidence interval
    """

    # Daily volatility
    daily_vol = realized_vol / np.sqrt(252)

    # Stop loss distance
    stop_distance = confidence * daily_vol

    # Stop price
    stop_price = entry_price * (1 - stop_distance)

    return {
        'stop_price': stop_price,
        'stop_distance_pct': stop_distance * 100,
        'daily_vol': daily_vol,
        'interpretation': f"Stop at {stop_distance*100:.2f}% below entry (2œÉ move)"
    }

# Ejemplo
entry = 100
vol_annual = 0.30
stop = volatility_based_stop_loss(entry, vol_annual, confidence=2.0)
# ‚Üí Stop at ~94.10 (5.9% below entry for 30% vol stock)
```

---

#### **2. Trailing Stop (Optimal Distance)**

**Han et al. (2016)** - "Optimal Trailing Stop Loss Rules"
- **Revista:** Quantitative Finance
- **Key Finding:** Optimal trailing stop = 20-25% for most stocks
- **Aplicaci√≥n:**
```python
def optimal_trailing_stop(prices, entry_price, method='ATR'):
    """
    Paper: Han et al. (2016)

    Methods:
    1. Fixed % (20-25% seg√∫n paper)
    2. ATR-based (2-3√ó ATR)
    3. Chandelier Exit
    """

    if method == 'FIXED':
        # Fixed 20% trailing stop (paper recommendation)
        trailing_pct = 0.20
        current_price = prices.iloc[-1]
        peak_price = prices[prices.index >= entry_price].max()
        stop_price = peak_price * (1 - trailing_pct)

    elif method == 'ATR':
        # ATR-based (more adaptive)
        high = prices.rolling(14).max()
        low = prices.rolling(14).min()
        close = prices

        tr1 = high - low
        tr2 = abs(high - close.shift())
        tr3 = abs(low - close.shift())
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        atr = tr.rolling(14).mean().iloc[-1]

        # Trailing stop at 2.5√ó ATR below peak
        peak_price = prices[prices.index >= entry_price].max()
        stop_price = peak_price - (2.5 * atr)

    elif method == 'CHANDELIER':
        # Chandelier Exit (Wilder)
        high_22 = prices.tail(22).max()
        atr_22 = calculate_atr(prices, 22)
        stop_price = high_22 - (3 * atr_22)

    return {
        'stop_price': stop_price,
        'distance_from_current': (prices.iloc[-1] - stop_price) / prices.iloc[-1] * 100,
        'method': method
    }
```

---

#### **3. Dynamic Stop Loss (Regime-Based)**

**Nystrup et al. (2020)** - "Dynamic Portfolio Optimization with Hidden Markov Models"
- **Revista:** Journal of Financial Econometrics
- **Key Finding:** Adjust stop loss seg√∫n market regime
- **Aplicaci√≥n:**
```python
def regime_based_stop_loss(prices, market_regime):
    """
    Paper: Nystrup et al. (2020)

    Regimes:
    - BULL (low vol): Wider stops (30%)
    - NORMAL: Standard stops (20%)
    - BEAR (high vol): Tighter stops (10-15%)
    """

    stop_distances = {
        'BULL': 0.30,      # Wide stops, let winners run
        'NORMAL': 0.20,    # Standard
        'BEAR': 0.12,      # Tight stops, capital preservation
        'CRISIS': 0.08     # Very tight, get out fast
    }

    stop_pct = stop_distances.get(market_regime, 0.20)

    current_price = prices.iloc[-1]
    stop_price = current_price * (1 - stop_pct)

    return {
        'stop_price': stop_price,
        'stop_pct': stop_pct,
        'regime': market_regime,
        'rationale': f"Wider stops in {market_regime} to avoid whipsaws" if market_regime == 'BULL'
                     else f"Tighter stops in {market_regime} for capital preservation"
    }
```

---

#### **4. Time-Based Stop Loss**

**Harvey & Liu (2021)** - "Lucky Factors"
- **Revista:** Journal of Financial Economics
- **Key Finding:** Holding periods matter; optimal 3-12 months for factors
- **Aplicaci√≥n:**
```python
def time_based_stop_loss(entry_date, holding_period_max=252):
    """
    Paper: Harvey & Liu (2021)

    Exit if:
    1. Holding period > max (e.g., 252 days = 1 year)
    2. Prevents stale positions
    """

    current_date = datetime.now()
    days_held = (current_date - entry_date).days

    time_stop_triggered = days_held >= holding_period_max

    return {
        'days_held': days_held,
        'max_holding_period': holding_period_max,
        'time_stop_triggered': time_stop_triggered,
        'action': 'EXIT' if time_stop_triggered else 'HOLD'
    }
```

---

## üìä **PARTE 3: Take Profit Strategies (2015-2024)**

### **üéØ Take Profit Mechanisms**

#### **1. Risk-Reward Ratio Based**

**Harris & Yilmaz (2019)** - "Optimal Position Sizing and Risk Management"
- **Revista:** Journal of Portfolio Management
- **Key Finding:** Optimal R:R ratio = 2:1 to 3:1
- **Aplicaci√≥n:**
```python
def risk_reward_take_profit(entry_price, stop_loss_price, rr_ratio=2.5):
    """
    Paper: Harris & Yilmaz (2019)

    Take Profit = Entry + (Risk √ó RR_Ratio)

    Example:
    - Entry: $100
    - Stop: $95 (risk = $5)
    - RR = 2.5
    - Take Profit = $100 + ($5 √ó 2.5) = $112.50
    """

    risk = entry_price - stop_loss_price
    reward = risk * rr_ratio
    take_profit_price = entry_price + reward

    return {
        'take_profit_price': take_profit_price,
        'risk_amount': risk,
        'reward_amount': reward,
        'rr_ratio': rr_ratio,
        'profit_pct': (reward / entry_price) * 100
    }
```

---

#### **2. Volatility-Scaled Take Profit**

**Homescu (2015)** - "Many Risks, One (Optimal) Portfolio"
- **Revista:** SSRN
- **Key Finding:** Scale targets por volatility regime
- **Aplicaci√≥n:**
```python
def volatility_scaled_take_profit(entry_price, realized_vol, base_target_pct=0.20):
    """
    Paper: Homescu (2015)

    Take Profit % = Base Target √ó (Median Vol / Current Vol)

    Logic:
    - Low vol ‚Üí higher % target (easier to achieve)
    - High vol ‚Üí lower % target (harder to achieve)
    """

    # Median volatility (typical stock ~25%)
    median_vol = 0.25

    # Adjustment factor
    vol_adjustment = median_vol / realized_vol

    # Adjusted target
    adjusted_target_pct = base_target_pct * vol_adjustment

    # Cap adjustments
    adjusted_target_pct = np.clip(adjusted_target_pct, 0.10, 0.40)

    take_profit_price = entry_price * (1 + adjusted_target_pct)

    return {
        'take_profit_price': take_profit_price,
        'target_pct': adjusted_target_pct * 100,
        'vol_adjustment': vol_adjustment,
        'interpretation': f"Target {adjusted_target_pct*100:.1f}% (adjusted for {realized_vol*100:.0f}% vol)"
    }
```

---

#### **3. Fibonacci Extensions (Quantified)**

**Ni & Yin (2023)** - "Technical Analysis Revisited"
- **Revista:** Journal of Financial Markets
- **Key Finding:** Fibonacci 1.618 extension tiene validaci√≥n emp√≠rica
- **Aplicaci√≥n:**
```python
def fibonacci_take_profit_levels(entry_price, swing_low, swing_high):
    """
    Paper: Ni & Yin (2023)

    Fibonacci Extensions: 1.272, 1.618, 2.618

    Validaci√≥n emp√≠rica:
    - 1.618 extension alcanzado en 40% de uptrends
    - Mejor usado con momentum confirmation
    """

    # Range
    range_size = swing_high - swing_low

    # Fibonacci extensions
    fib_1272 = swing_high + (range_size * 0.272)
    fib_1618 = swing_high + (range_size * 0.618)  # Golden ratio
    fib_2618 = swing_high + (range_size * 1.618)

    return {
        'tp_conservative': fib_1272,
        'tp_moderate': fib_1618,      # ‚Üê Most common
        'tp_aggressive': fib_2618,
        'probability_1618': 0.40,     # From paper
    }
```

---

#### **4. Statistical Take Profit (Percentile-Based)**

**Lopez de Prado (2020)** - "Advances in Financial Machine Learning"
- **Libro:** Wiley (Cap√≠tulo sobre exits)
- **Key Finding:** Use historical return distribution
- **Aplicaci√≥n:**
```python
def statistical_take_profit(historical_returns, holding_period=20, percentile=75):
    """
    Paper: Lopez de Prado (2020)

    Take Profit = X percentile of historical N-day returns

    Example:
    - 75th percentile of 20-day returns
    - Conservative: 60th percentile
    - Aggressive: 90th percentile
    """

    # Calculate N-day returns
    n_day_returns = historical_returns.rolling(holding_period).apply(
        lambda x: (x + 1).prod() - 1
    )

    # Percentile
    target_return = np.percentile(n_day_returns.dropna(), percentile)

    # Probability of reaching target
    prob_reach = (n_day_returns >= target_return).mean()

    return {
        'target_return_pct': target_return * 100,
        'probability': prob_reach,
        'percentile': percentile,
        'interpretation': f"{percentile}th percentile = {target_return*100:.1f}% gain in {holding_period} days"
    }
```

---

#### **5. Machine Learning-Based Exit**

**Dixon et al. (2020)** - "Deep Reinforcement Learning for Trading"
- **Revista:** Journal of Financial Data Science
- **Key Finding:** RL agents learn optimal exit timing
- **Aplicaci√≥n:**
```python
from stable_baselines3 import PPO

def ml_based_exit_signal(state_features):
    """
    Paper: Dixon et al. (2020)

    State features:
    - Days held
    - Current P&L %
    - Momentum indicators
    - Volatility
    - Market regime

    Action: HOLD, PARTIAL_EXIT, FULL_EXIT
    """

    # Load pre-trained RL agent
    model = PPO.load("exit_timing_agent.zip")

    # Predict action
    action, _states = model.predict(state_features, deterministic=True)

    # Interpret
    actions_map = {
        0: 'HOLD',
        1: 'PARTIAL_EXIT_50',
        2: 'FULL_EXIT'
    }

    return {
        'action': actions_map[action],
        'confidence': model.policy.get_distribution(state_features).entropy()
    }
```

---

## üìä **PARTE 4: Position Sizing (Modern)**

**Kelly Criterion (Modernizado)**

**Rotando & Thorp (2018)** - "The Kelly Capital Growth Investment Criterion"
- **Libro:** World Scientific (3rd edition)
- **Aplicaci√≥n:**
```python
def kelly_position_sizing(win_rate, avg_win, avg_loss, kelly_fraction=0.25):
    """
    Paper: Rotando & Thorp (2018)

    Kelly % = (Win Rate √ó Avg Win - Loss Rate √ó Avg Loss) / Avg Win

    Commonly use fractional Kelly (25-50%) to reduce variance
    """

    loss_rate = 1 - win_rate

    # Kelly formula
    kelly_pct = (win_rate * avg_win - loss_rate * avg_loss) / avg_win

    # Fractional Kelly (safer)
    fractional_kelly = kelly_pct * kelly_fraction

    # Cap position size
    position_size = np.clip(fractional_kelly, 0.01, 0.20)  # Max 20% per position

    return {
        'kelly_full': kelly_pct,
        'kelly_fractional': fractional_kelly,
        'recommended_position_size': position_size,
        'interpretation': f"Allocate {position_size*100:.1f}% of portfolio"
    }
```

---

## üéØ **RESUMEN: Mejoras Propuestas para V4**

### **1. Factor Investing Moderno**
- ‚úÖ **Momentum Crash Detection** (Daniel & Moskowitz 2016)
- ‚úÖ **Factor Momentum Rotation** (Ehsani & Linnainmaa 2022)
- ‚úÖ **ML Stock Ranking** (Gu, Kelly & Xiu 2020)
- ‚úÖ **Volatility Scaling** (Moreira & Muir 2017)

### **2. Stop Loss System**
- ‚úÖ **Volatility-Based Stops** (Kaminski & Lo 2014)
- ‚úÖ **Trailing ATR Stops** (Han et al. 2016)
- ‚úÖ **Regime-Based Stops** (Nystrup et al. 2020)
- ‚úÖ **Time-Based Exits** (Harvey & Liu 2021)

### **3. Take Profit System**
- ‚úÖ **Risk-Reward Targets** (Harris & Yilmaz 2019)
- ‚úÖ **Volatility-Scaled Targets** (Homescu 2015)
- ‚úÖ **Statistical Percentiles** (Lopez de Prado 2020)
- ‚úÖ **ML-Based Exits** (Dixon et al. 2020)

### **4. Position Sizing**
- ‚úÖ **Volatility-Managed Sizing** (Moreira & Muir 2017)
- ‚úÖ **Kelly Criterion** (Rotando & Thorp 2018)

---

## üìö **Lista Completa de Papers (2015-2024)**

### **Momentum & Factors**
1. Geczy & Samonov (2016) - "Two Centuries of Price-Return Momentum"
2. Daniel & Moskowitz (2016) - "Momentum Crashes"
3. Ehsani & Linnainmaa (2022) - "Factor Momentum and the Momentum Factor"

### **Machine Learning**
4. Gu, Kelly & Xiu (2020) - "Empirical Asset Pricing via Machine Learning" ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
5. Chen, Pelger & Zhu (2024) - "Deep Learning in Asset Pricing"
6. Dixon et al. (2020) - "Deep Reinforcement Learning for Trading"

### **Liquidity**
7. Barardehi et al. (2023) - "Measuring Market Liquidity"
8. Pastor & Stambaugh (2023) - "Liquidity Risk and Expected Returns" (updated)

### **Risk Management**
9. Moreira & Muir (2017) - "Volatility-Managed Portfolios" ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
10. Barroso & Santa-Clara (2015) - "Momentum Has Its Moments"
11. Nystrup et al. (2020) - "Dynamic Portfolio Optimization with Hidden Markov Models"

### **Stop Loss & Exits**
12. Kaminski & Lo (2014) - "When Do Stop-Loss Rules Stop Losses?"
13. Han et al. (2016) - "Optimal Trailing Stop Loss Rules"
14. Harvey & Liu (2021) - "Lucky Factors"

### **Take Profit**
15. Harris & Yilmaz (2019) - "Optimal Position Sizing and Risk Management"
16. Homescu (2015) - "Many Risks, One (Optimal) Portfolio"
17. Ni & Yin (2023) - "Technical Analysis Revisited"

### **Position Sizing**
18. Rotando & Thorp (2018) - "The Kelly Capital Growth Investment Criterion"
19. Lopez de Prado (2020) - "Advances in Financial Machine Learning"

---

## üöÄ **Pr√≥ximo Paso**

¬øQu√© parte quieres que implemente primero?

**A)** Stop Loss System (volatility-based + trailing)
**B)** Take Profit System (R:R + statistical)
**C)** ML Ranking (Gu et al. 2020 implementation)
**D)** Volatility Management (Moreira & Muir 2017)
**E)** Todo integrado (V4 completo, 2-3 semanas)

Dime y empiezo con c√≥digo de producci√≥n! üéØ
